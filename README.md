# Semantic Segmentation on Cityscapes Dataset 


## ğŸ§  Introduction

Semantic segmentation is a key task in computer vision that involves classifying every pixel in an image into predefined categories. It's widely used in:
- **Autonomous driving** (e.g., identifying roads, vehicles, pedestrians)
- **Medical imaging** (e.g., tumor detection)
- **Urban scene understanding**

This project uses the **Cityscapes dataset**, which contains 5000 finely annotated urban street scene images. Due to limited access to test images, **validation accuracy** is the main performance metric.

---

## ğŸ§© Project Overview

Our approach consisted of the following key steps:

1. ğŸ“Š **Dataset Analysis** â€“ Understanding Cityscapes format and valid classes  
2. ğŸ§¼ **Preprocessing** â€“ Image resizing, encoding masks, color remapping  
3. ğŸ–¼ï¸ **Visualization** â€“ Input images and corresponding masks  
4. ğŸ—ï¸ **Model Development** â€“ Trying various architectures  
5. ğŸ¯ **Loss Functions** â€“ Experimenting with standard and custom ones  
6. ğŸ§ª **Post-Processing** â€“ Applying CRF (Conditional Random Fields)  
7. ğŸ“‰ **Evaluation** â€“ Using validation accuracy and IOU  

---

## ğŸ› ï¸ Approaches & Architectures

### 1. ğŸ§¬ UNet (Baseline)
- Basic encoder-decoder with skip connections
- Input Size: `256x256`
- **Accuracy**: `83.80%`
- Used primarily to validate preprocessing pipeline

---

### 2. ğŸ§  DeepLabV3+ (Best Performing)
- Backbone: `ResNet-50 pretrained on ImageNet`
- Concepts: `Atrous Convolution`, `ASPP`
- Input Size: `256x512`
- **Accuracy**: `87.29%`
- Custom loss with Sobel edge filter
- Tried CRF post-processing (minimal improvement)

---

### 3. ğŸ” Attention ResUNet
- Introduced attention gates and residual connections
- Input Size: `128x128`
- **Accuracy**: `82.40%`
- Attention helped focus on spatially important regions

---

### 4. ğŸŒ PSPNet
- Used Pyramid Pooling for global + local context
- Input Size: `128x128`
- **Accuracy**: `82.10%`

---

### 5. ğŸ¦¾ YOLOv8 (Detection-based Attempt)
- Attempted object detection on Cityscapes
- Objective: Fine-tune for semantic regions like sky, road, buildings
- **Result**: Limited success due to incomplete fine-tuning

---

## â›” Blockers Faced

- âŒ GPU crashes on higher input resolutions
- âš ï¸ Directory mismatches and shape errors in training
- âš™ï¸ Debugging preprocessing pipelines and label encoding
- ğŸ§® Required one-hot encoding + categorical cross-entropy in some models

---

## ğŸ“Š Results Summary

| S. No | Model                   | Input Resolution | Validation Accuracy |
|-------|-------------------------|------------------|---------------------|
| 1     | PSPNet                  | 128x128          | 82.10%              |
| 2     | Attention ResUNet       | 128x128          | 82.40%              |
| 3     | Basic UNET              | 256x256          | 83.80%              |
| 4     | DeepLabV3+              | 256x512          | 87.16%              |
| 5     | DeepLabV3+ (Custom Loss)| 256x512          | **87.29%**          |

---

## ğŸš€ Future Work

- ğŸ“ˆ **Data Augmentation** to enrich training samples  
- ğŸ” **Higher input resolutions** for sharper segmentations  
- ğŸ“ **Optimizing IOU/Jaccard scores** directly as training objectives  
- ğŸ§© Try **Dice / Tversky / Focal / Lovasz** losses  
- ğŸ” **Improved dilation schemes** for broader receptive fields  
- ğŸ“¦ **Complete YOLO finetuning** for semantic regions  

---

## ğŸ“ Dataset

- Source: [Cityscapes Dataset](https://www.cityscapes-dataset.com/)
- Used: `gtFine` (masks) and `leftImg8bit` (images)
- Test set not accessible â†’ **Validation set used exclusively**

---

## ğŸ“· Sample Outputs

Visual comparisons between ground truth and predicted masks are available in the project folder. UNet and DeepLab outputs show clear pixel-wise labeling, with DeepLab producing the sharpest segmentations.

---

## ğŸ“š References

- [UNet](https://arxiv.org/abs/1505.04597)  
- [DeepLabV3+](https://arxiv.org/abs/1802.02611)  
- [Attention UNet](https://arxiv.org/abs/1804.03999)  
- [PSPNet](https://arxiv.org/abs/1612.01105)  
- [YOLOv8](https://github.com/ultralytics/ultralytics)


